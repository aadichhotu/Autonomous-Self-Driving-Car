{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "#pip install numpy\n",
    "#pip install opencv-python-headless\n",
    "#pip install matplotlib\n",
    "#pip install scikit-learn\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing requirements \n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,Flatten,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data extractor \n",
    "def importData(main_folder):\n",
    "\n",
    "    csv_paths = []\n",
    "\n",
    "    for i in os.listdir(main_folder):\n",
    "        sub_path =  main_folder +'/'+ i \n",
    "        for csv_file in os.listdir(sub_path):\n",
    "            if(csv_file.endswith(\".csv\")):\n",
    "                csv_path = sub_path + \"/\" + csv_file\n",
    "                if(os.path.exists(csv_path)):\n",
    "                    csv_paths.append(csv_path)\n",
    "    \n",
    "    data_frames = []\n",
    "\n",
    "    for file_index in range(len(csv_paths)):\n",
    "        csv_file_path = csv_paths[file_index]\n",
    "\n",
    "        dataframe = pd.read_csv(csv_file_path)\n",
    "        imageFilePath = os.path.dirname(csv_file_path)\n",
    "\n",
    "        dataframe['imageName'] = imageFilePath + \"/\" + dataframe['imageName'] + \".jpg\"\n",
    "        data_frames.append(dataframe)\n",
    "\n",
    "    data = pd.concat(data_frames, ignore_index=True)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceData(data,display=True):\n",
    "    nBin = 31\n",
    "    samplesPerBin =  500\n",
    "    zeroAngleBinSample = samplesPerBin\n",
    "    hist, bins = np.histogram(data['steeringAngle'], nBin)\n",
    "    if display:\n",
    "        center = (bins[:-1] + bins[1:]) * 0.5\n",
    "        plt.bar(center, hist, width=0.03)\n",
    "        plt.plot((np.min(data['steeringAngle']), np.max(data['steeringAngle'])), (samplesPerBin, samplesPerBin))\n",
    "        plt.title('Data Visualisation')\n",
    "        plt.xlabel('Steering Angle')\n",
    "        plt.ylabel('No of Samples')\n",
    "        plt.show()\n",
    "    removeindexList = []\n",
    "    for j in range(nBin):\n",
    "        binDataList = []\n",
    "        for i in range(len(data['steeringAngle'])):\n",
    "            if data['steeringAngle'][i] >= bins[j] and data['steeringAngle'][i] <= bins[j + 1]:\n",
    "                binDataList.append(i)\n",
    "        binDataList = shuffle(binDataList)\n",
    "        if j!=15:\n",
    "            binDataList = binDataList[samplesPerBin:]\n",
    "        else:\n",
    "            binDataList = binDataList[zeroAngleBinSample:]\n",
    "        removeindexList.extend(binDataList)\n",
    "\n",
    "    print('Removed Images:', len(removeindexList))\n",
    "    data.drop(data.index[removeindexList], inplace=True)\n",
    "    print('Remaining Images:', len(data))\n",
    "    if display:\n",
    "        hist, _ = np.histogram(data['steeringAngle'], (nBin))\n",
    "        plt.bar(center, hist, width=0.03)\n",
    "        plt.plot((np.min(data['steeringAngle']), np.max(data['steeringAngle'])), (samplesPerBin, samplesPerBin))\n",
    "        plt.title('Balanced Data')\n",
    "        plt.xlabel('Steering Angle')\n",
    "        plt.ylabel('No of Samples')\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = importData(\"D:/3_Education/My Comp/Business_Analytics/Business_analytics_python/07_Raspberry Pi/YouTube Video/05_CNN_Training/01_Input_Data\")\n",
    "data = balanceData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing \n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "def image_preprocessor(image):\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    img = cv2.GaussianBlur(img,  (3, 3), 0)\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "def get_xyTrain(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        filepath = row[dataframe.columns[0]]\n",
    "        angle = row[dataframe.columns[1]]\n",
    "\n",
    "        img = cv2.imread(filepath)\n",
    "        processed_img = image_preprocessor(img)\n",
    "        x_data.append(processed_img)\n",
    "        y_data.append(angle)\n",
    "    \n",
    "    return np.asarray(x_data), np.asarray(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train split \n",
    "x_data_np, y_data_np = get_xyTrain(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data_np, y_data_np, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training without ImageGen \n",
    "\n",
    "#### STEP-7 : CREATE MODEL\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), (2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
    "    model.add(Convolution2D(36, (5, 5), (2, 2), activation='elu'))\n",
    "    model.add(Convolution2D(48, (5, 5), (2, 2), activation='elu'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='elu'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='elu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = 'elu'))\n",
    "    model.add(Dense(50, activation = 'elu'))\n",
    "    model.add(Dense(10, activation = 'elu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    \n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_1=3\n",
    "model = createModel()\n",
    "history = model.fit(X_train,y_train,validation_split=0.3,epochs=epoch_1,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = [i for i in range(epoch_1)]\n",
    "loss_train = history.history['loss']\n",
    "loss_test = history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss_train, color='blue', label='Train Loss')\n",
    "plt.plot(epochs, loss_test, color='orange', label='Validation Loss')\n",
    "plt.title('Train and Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Define the save directory\n",
    "save_dir = \"D:/3_Education/My Comp/Business_Analytics/Business_analytics_python/07_Raspberry Pi/YouTube Video/05_CNN_Training/03_Model_file\"\n",
    "\n",
    "# Get the current time\n",
    "current_time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "# Create the full model filename\n",
    "model_filename = os.path.join(save_dir, f\"model_{current_time}.h5\")\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to tflite \n",
    "#representative dataset for Int8 Quantization\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "def representative_data_gen():\n",
    "      for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "tf_model_filename = os.path.join(save_dir, f\"model_{current_time}.tflite\")\n",
    "#save the model\n",
    "with open(tf_model_filename, 'wb') as f:\n",
    "      f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference engine by tflite runtime\n",
    "#import tflite_runtime.interpreter as tflite_interp\n",
    "\n",
    "def Inference_Engine(model_path, image):\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    #print(\"[+]expected input shape:\", input_shape)\n",
    "    input_type = input_details[0]['dtype']\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        #print(\"[+]allocating tensor\")\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        #internal processing\n",
    "        input_tensor = np.array(image).astype(input_type)\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "        #inference \n",
    "        #print(\"[+]performing inference\")\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        #print(\"[+]inference completed\")\n",
    "        return output\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"[-]caught exception: \", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num = 5\n",
    "output = Inference_Engine(tf_model_filename, X_test[row_num])\n",
    "print('Actual_str_angle',int(y_test[row_num]*25))\n",
    "print('Predicted_str_angle',int(output*25))\n",
    "error = int(y_test[row_num]*25)-int(output*25)\n",
    "print('error', error)\n",
    "img = X_test[row_num]\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img, cmap=None)\n",
    "ax.set_title('Your YUV Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
